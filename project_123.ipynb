{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import export_graphviz\n",
    "from io import StringIO\n",
    "from IPython.display import Image\n",
    "from pydot import graph_from_dot_data\n",
    "import graphviz\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "#from adspy_shared_utilities import (plot_class_regions_for_classifier_subplot)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=10)\n",
    "\n",
    "df = pd.read_csv(Values.csv\", index_col=None, na_values='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns 'File Name' and 'source' does not have significant effect on the response variable 'channels', so dropping column 'Filename' and 'source'...\n",
    "df = df.drop(['File Name', 'Source'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 214, 248, 371 have many missing values in the dataset, so removing these rows...\n",
    "df = df.drop(index=[214, 248, 371], axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing percentage symbols from data....\n",
    "for i in df.columns[:-1]:\n",
    "    df[i] = [float(str(j).replace('%', '')) for j in df[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Channels'] = LabelEncoder().fit_transform(df['Channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert categorical predictors...\n",
    "df = pd.get_dummies(df, columns=['Sample Rate (Hz)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mean values for missing values...\n",
    "for j in col_missing_values:\n",
    "    mean = np.mean(df[j])\n",
    "    for i in range(len(df[j])):\n",
    "        try:\n",
    "            if str(df[j][i]) == 'nan':\n",
    "                df[j][i] = mean\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "# Display first 10 rows...\n",
    "df.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns in order...\n",
    "temp_df = df['Channels']\n",
    "df = df.drop(['Channels'], axis = 1)\n",
    "df = df.join(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df.iloc[:, :-1]\n",
    "Y_data = df['Channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating scatter plot matrix...\n",
    "pd.plotting.scatter_matrix(X_data, c = Y_data, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correlation matrices...\n",
    "\n",
    "# response-predictor correlation...\n",
    "r_p_corr = df.corr()\n",
    "print('Correlation matrix of response-predictor')\n",
    "print(r_p_corr)\n",
    "plt.figure(figsize = (30, 25), num =2)\n",
    "plt.title('Response-Predicitor pairwise correlation')\n",
    "sns.heatmap(r_p_corr, annot = True, cmap=\"PuBuGn_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predictor-predictor correlation...\n",
    "p_p_corr = X_data.corr()\n",
    "print('Correlation matrix of predictor-predictor')\n",
    "print(p_p_corr)\n",
    "\n",
    "plt.figure(figsize = (30, 25), num = 3)\n",
    "plt.title('Predictor-Predicitor pairwise correlation')\n",
    "sns.heatmap(p_p_corr, annot = True, cmap=\"RdYlBu_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ANOVA table...\n",
    "X_data = sm.add_constant(X_data)\n",
    "stat_model = sm.OLS(np.array(Y_data), np.array(X_data))\n",
    "res = stat_model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From correlation matrix it can be observed that sample rate 48000 HZ and Sixe on Memory are highly correlated, therefore dropping size on memory...\n",
    "df = df.drop(['Size on memory  (kB)'], axis = 1)\n",
    "X_data = df.iloc[:, :-1]\n",
    "Y_data = df['Channels']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c34d76f7263c545493e7b33b4c33221f434d69469ad7223d3a45cc2eac8f3ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
